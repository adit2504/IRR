\documentclass[journal]{IEEEtran}
\usepackage{cite}
\usepackage{placeins}
\usepackage{upgreek}
\ifCLASSINFOpdf
 \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
 \graphicspath{{Pics/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
\fi
\hyphenation{op-tical net-works semi-conduc-tor}
\begin{document}
\title{Ultra Low Energy Microcontroller Architectures}
\author{Aditya Tandon,~\IEEEmembership{at3g10@soton.ac.uk,~University of Southampton} 
\thanks{}}
% The paper headers
\markboth{Individual Research Review} %
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
\maketitle

\begin{abstract}
%\boldmath
Wireless sensor network (WSN) applications and mobile processors require low energy architectures for them to be commercially viable. In wireless networks, a device can run for years without change in battery and batteries on mobile phones need to have an extended lifetime so that the user does not have to constantly charge the phone. To cater to these needs, various low power design techniques have cropped up to reduce power on processors. This paper highlights some of these techniques that can be useful for WSN applications and mobile processors. Concepts such as asynchronous design, subthreshold design, low power memory design and power domains have been explained to show the different ways in which energy can be saved.  Every scheme has shown a reduction in energy with trade-offs for performance, cost and area. This is a minor trade-off as the life of a product is increased due to these low power techniques.
\end{abstract}
\IEEEpeerreviewmaketitle

\section{Introduction}
\IEEEPARstart{M}{any} applications in today’s world demand minimal energy consumption. In wireless sensor networks, a system might be placed in a remote location where the battery cannot be changed periodically. It could also derive energy from the environment and hence has to function on the least amount of energy as possible. On the other end, mobile processors these days have become very sophisticated. They have to perform a variety of tasks such as calling, streaming videos, playing music etc. and at the same time ensure that the battery lasts for a long time. This report looks into the different approaches that can be employed to design low energy microcontrollers and microprocessors. There are many established techniques that are being used in industry and there are other topics that are still in the research stage. This report aims to provide a mix of both approaches to highlight the most relevant methods that can be adopted to produce an efficient architecture. \\

Section II of the report deals with asynchronous processors and how they can be applied in wireless sensor applications. Section III describes different low power memory techniques to reduce power and Section IV talks about how design in the subthreshold region can lead to energy savings. Section V highlights some emerging power management schemes such as the use of power domains and also explains how established techniques such as dynamic voltage and frequency scaling can be improved. Section VI highlights other alternative methods for low power design such as the use of FPGAs and Section VII concludes this paper.

\section{Asynchronous design}
In the field of sensor networks asynchronous processors and microcontrollers have been gaining popularity as they lead to energy efficient designs. The basic principle is that these designs function without a global clock and hence reduce the number of unwanted switching activities in the circuit \cite{SNAP/LE}, \cite{LowPower2005}, \cite{FPGAEvent}. To compensate for no clock, the designs usually employ extra hardware for a handshaking protocol \cite{SNAP/LE}, \cite{FPGAEvent}. To further conserve energy these designs are event driven \cite{SNAP/LE}, \cite{LowPower2005}, \cite{FPGAEvent}, \cite{AVR}. In such a system, the controller is mostly in a state of sleep until it is asked to perform a computation by an event. After performing the task the controller goes back to a sleep state thereby minimizing its active energy \cite{SNAP/LE}, \cite{LowPower2005}. Research has shown that there is no necessary software overhead for these systems due to their event driven nature \cite{SNAP/LE}, \cite{LowPower2005}. This is because these microcontrollers are used for a set of pre-defined tasks and can be simplified. For example, interrupts can be processed as events and there is no overhead to handle concurrent tasks \cite{SNAP/LE}, \cite{LowPower2005}. Designs can be further simplified by employing an in-order design which reduces the amount of hardware and therefore lowers energy \cite{LowPower2005}, \cite{SmartDust}. \\

Event driven architectures should have a minimal transition time from a sleep state to an active state. The SNAP/LE architecture addresses this concern by employing an event queue \cite{SNAP/LE}. This resembles a FIFO handler and tasks are executed if there is an event token present in the queue. An event token signifies an event. If there is a token, the appropriate event handler associated with the token is looked up and the task is executed. After executing the task the processor goes into a 'sleep' state if there is no token present \cite{SNAP/LE}. The time taken by the processor to transition between an active and sleep state is the time taken for a token to go through the event queue \cite{SNAP/LE}. The length of the queue can be optimized so that this process is in the order of tens of nanoseconds and therefore this procedure saves energy \cite{SNAP/LE}. \\

Typically these designs can be modularised and stress can be taken off the microcontroller by employing hardware accelerators \cite{SNAP/LE}, \cite{LowPower2005}. Hempstead et al. \cite{LowPower2005} used the microcontroller only for computational intensive tasks and a separate event processor was employed which was effectively a hard-coded state machine to handle events which required light computation. This reduced the active and leakage power of the main controller. Another type of accelerator used was the 'Message Coprocessor' which was responsible for forming and forwarding incoming messages from the radio unit. Timing operations commonly found in wireless applications can be handled by a Timer Coprocessor and therefore can lead to a simplistic, energy efficient implementation for the microcontroller at the expensive of some additional hardware \cite{LowPower2005}. An architectural implementation of such a system can be seen from Figure \ref{Figure:Async}. \\
	
	\begin{figure}[h]
	   \centering
	   \includegraphics[width = 8cm]{Async}
	   \caption{Event driven design (reproduced from \cite{LowPower2005}).}
	   \label{Figure:Async}
	\end{figure}	
	\FloatBarrier
	
The steps taken in desynchronization involve replacing the clock tree with local, asynchronous controllers and converting the flip-flops into latches \cite{AVR}. This was demonstrated by Neechi et al. \cite{AVR} where a synchronous AVR microcontroller was used as a template to create an asynchronous version. It was found that the asynchronous controller was about 5 times more energy efficient than the synchronous one \cite{AVR}. The amount of energy that these prototype processors have taken to execute a particular instruction has been in the range of 10pJ – 14pJ assuming an operating voltage of 1.2V and about 2.7pJ/instruction at 0.54V \cite{SNAP/LE}, \cite{AVR}, \cite{SmartDust}.
	 
\section{Low power memory}
Over the years researchers have come up with different techniques to mitigate energy loss due to memory. A proposal for an adaptive cache for mobile processors could help reduce power \cite{Mem-Cache}. The L2 caches on mobile phones have been found to have access patterns that are not correlated or balanced and therefore there is scope to dynamically adjusting the cache to match the application using it \cite{Mem-Cache}. The compiler does an offline analysis of the application before run-time to determine parameters such as global average miss rates and access rates. Cache access is also monitored during run-time and this information in conjunction with the offline material is used to enlarge or decrease the size of the cache dynamically depending on the need \cite{Mem-Cache}. This proves useful as memory is used much more efficiently. Also, the leakage power is reduced as there are fewer idle cells. This technique was found to give a 13\% - 29\% reduction in power consumption (using benchmark programs) but there was a small trade-off for speed and area to incorporate this \cite{Mem-Cache}.\\

	\begin{figure}[h]
	   \centering
	   \includegraphics[width = 5cm]{AdaptiveCache}
	   \caption{Adaptive cache design (reproduced from \cite{Mem-Cache}).}
	   \label{Figure:Mem-Cache}
	\end{figure}	
	\FloatBarrier

Another technique to reduce power is memory compression \cite{MemComp}. Here, a part of the data in volatile memory is compressed in order to reduce the number of logic elements that have to be self-refreshed when a device is turned into a low power state. Rest of the memory can be powered off and therefore the battery life is extended \cite{MemComp}. When there is a request to put a device into a low power state, the memory compression logic takes blocks from a designated memory, compresses it using a compression algorithm and then stores these blocks back to memory. A decompression procedure is followed when the device moves into an active state \cite{MemComp}. The compression logic can be implemented in hardware or software and induces some overhead on the battery while performing compression but the power saved by compressing data outweighs this overhead \cite{MemComp}.\\

Non-volatile memories are another area of interest for power reduction and even in performance enhancement \cite{NonVolatile}. Resistive Random Access Memory (RRAM) is a piece of memory that could be used as a substitute for SRAMs on mobile devices \cite{NonVolatile}, \cite{RRAMSwitch}. It was found that an RRAM with a crosspoint structure that uses a diode as a select cell reduces leakage current. This is because the resistance goes up as voltage decreases and the leakage current paths are cut-off \cite{NonVolatile}. This structure is also area efficient as multi-layered structures can be made \cite{NonVolatile}. Investigation is still going into this area as peripheral circuit design is harder if RRAMs are used but it could be used as a technique to reduce energy and power \cite{NonVolatile}. Alternative RRAM technologies are also being researched and a switching energy of 6fJ has been achieved and this is close to the switching energy of Flash Memory \cite{RRAMSwitch}. \\

Many other techniques can be used to reduce power. An Intel processor for mobile devices reduces the leakage power in the L2 cache \cite{Intel}. The data arrays in the cache continue to be in the 'sleep' mode until a 'Hit' signal is generated. Even when there is a hit, only the relevant data array is charged so that it can be activated while the other arrays continue to be in the low power mode \cite{Intel}. This is a memory partitioning technique and is widely used to mitigate leakage power \cite{Intel}, \cite{L2Mobile}.

\section{Subthreshold design}
Devices operating in the subthreshold region show a reduction in energy because the switching activity decreases with supply voltage \cite{FFT}, \cite{MemSub}. However, the propagation delay increases in this region which gives rise to leakage currents. This can cause energy dissipation \cite{FFT}, \cite{MemSub}. There exists an optimal operating point in the subthreshold region at which devices can operate. This point can be found through a minimum energy analysis technique in which the energy is plotted against the supply voltage as the voltage is scaled down \cite{FFT}. Wang and Chandrakasan \cite{FFT} implemented this idea in a FFT processor to demonstrate how devices can operate in subthreshold regions. Logic elements have to be specifically modified to be catered for subthreshold operation to avoid leakage current. Parallel leakage is a major contributor to leakage current and it occurs when the idle current is comparable to the drive current in circuits \cite{FFT}. This effect can be mitigated by reducing or balancing the number of parallel devices in the pull up and pull down path to avoid leakage \cite{FFT}. Devices should avoid being stacked as this reduces the effective drive current of each transistor in a stack \cite{FFT}. \\

RAM blocks usually contain a six transistor (6T) scheme to enable reading and writing of data. Wang and Chandrakasan have demonstrated that subthreshold conditions make read and write operations harder as they place a sizing constraints on the transistors used \cite{FFT}. There are also other considerations such as bitline leakage that comes into effect when operating in this region \cite{FFT}. Therefore, an alternative structure to the RAM is needed to address this problem. In the FFT processor, the RAM uses tristate inverters to create a latch and this is used for write operations. The read operation uses parallel tristate gates and a hierarchical read bitline to mitigate parallel leakage \cite{FFT}. \\

Therefore, it can be observed that operating in the subthreshold region can help in energy savings but only if the logic is suitably catered for it. Designers might have to construct subthreshold libraries if they want their devices operating in this region. The gains in the long run are satisfactory as it results in an energy efficient device.  The subthreshold FFT chip that was made was found to be ``350 times more energy efficient than the low-power microprocessor implementation'' which was a microprocessor that did not include subthreshold logic \cite{FFT}.


\section{Power management schemes}
\subsection{Power domains and other techniques}
Chips on mobile phones are now moving towards a multi-core implementation to support the vast functionality that is in demand. The cores are usually heterogeneous so that each of them can run at an independent frequency and hence be utilized in the best possible way and also reduce dynamic power \cite{HierarchicalPower}. A single chip implementation makes it hard for power management schemes to achieve power reduction due to leakage currents. A multi-chip implementation paves way to implementing a partial power off scheme where unused chips can be powered off if they are not in use \cite{HierarchicalPower}. This gives rise to the concept of a power domain where different parts of a chip and also different chips can be isolated from each other in terms of power management \cite{HierarchicalPower}. Many domains can thus be created and power can be saved. Implementing power domains does pose some problems. For example, the shutdown elements between power domains need to be robust and reliable \cite{HierarchicalPower}. $\mu$I/O’s are used to route signals from domains that might be powered off. These are special circuits used to isolate such signals \cite{HierarchicalPower}. To minimize such additional circuitry, a hierarchical power domain scheme can be adopted which sets a level of precedence for certain domains \cite{HierarchicalPower}. So no $\mu$I/O’s are needed from a higher hierarchy to a lower one as the lower hierarchy cannot be active while the upper one is switched off. Figure \ref{Figure:Hier} illustrates a hierarchical structure that can be implemented on mobile phones.

	\begin{figure}[h]
	   \centering
	   \includegraphics[width = 7cm]{Hier}
	   \caption{Hierarchical power domains (reproduced from \cite{HierarchicalPower}).}
	   \label{Figure:Hier}
	\end{figure}	
	\FloatBarrier

Another problem is the rush current generated while switching on power domains \cite{HierarchicalPower}. Hattori et al. \cite{HierarchicalPower} described an efficient power switch design to minimize this rush current so that it can be made negligible. They observed very low leakage currents using this design and so the use of hierarchical power domains could be an effective way to save energy \cite{HierarchicalPower}. \\

Power gating is another strategy that has been around for quite a while. Here, the processor is switched off due to switches inserted into the power rail \cite{LDO}. This causes a reduction in power but other components, such as state retention registers, power management unit and Low Drop Regulator (LDO) still remain active and contribute to leakage current \cite{LDO}. To mitigate this, Lueders et al. \cite{LDO} proposed a scheme based around the LDO. The idea was that a digitally adaptive LDO would drive the micro-controller unit and based on the requirements, it would adapt its drive current and hence reduce power management overhead in low frequency operations \cite{LDO}. Also, as the LDO is integrated onto the chip, it would be designed with a low output capacitance and therefore take up very little power during sleep and also have a quick transition wake up time \cite{LDO}. During sleep mode, the LDO can be disabled and it was shown that a power saving of a factor of 4.3 was achieved as compared to power gating \cite{LDO}. This was easier to implement than power gating as system partitioning was simple and no power switches had to be used \cite{LDO}. \\

Other power management schemes, include the implementation of different power states in a system \cite{Intel}. For example, an Intel processor for mobile phones has 6 power states (C0 – C6) \cite{Intel}. The C0 state is the high frequency state and in C6 state the core power is shutdown \cite{Intel}. The intermediate states involve the power gating of different components such as the core clock, phase locked loops and flushing of L1 caches to reduce dynamic power \cite{Intel}.   


\subsection{Dynamic voltage and frequency scaling}

Dynamic voltage and frequency scaling (DVFS) is used ubiquitously to improve energy performance in processors \cite{LinuxGov}, \cite{TempDVFS}, \cite{48Core}. Power is proportional to frequency and the square of supply voltage so scaling down these parameters saves energy \cite{TempDVFS}. Although delay increases with a reduced voltage, applications that are not time critical can be performed at a lower voltage to avoid performance hits \cite{LinuxGov}. Multicores on mobile phones can be made much more energy efficient if they ran at an optimum operating point. This operating point is a combination of choosing the correct operating frequency and the number of cores used for an application \cite{LinuxGov}. Quite often, cores are under-utilized in order to save energy but this actually dissipates more energy as fewer cores are running intensive programs at a higher frequency. Instead of this, more cores can be made available and can operate at a lower frequency \cite{LinuxGov}, \cite{MultiCores}. This increases the number of computation resources and also reduces the energy as the operating frequency is low. Also, the work gets executed faster and power dissipation outside the cores can be minimized as these components can be turned off once the computation is finished \cite{LinuxGov}, \cite{MultiCores}. Carol and Heiser \cite{LinuxGov} have come up with a linux governor that implements this concept. Frequency is increased if a core is being over-utilized and vice versa. It also disables and enables cores based on their need and this could be a useful tool to incorporate onto devices as an energy saving of upto 25\% was observed in this case \cite{LinuxGov}.\\

Dynamic Thermal Management (DTM) is another important aspect to consider when discussing DVFS \cite{TempDVFS}. If the temperature of a chip exceeds a certain thermal threshold the frequency has to be scaled down again to prevent the chip from over-heating. Once the temperature goes down the frequency is increased again and this would result in the thermal threshold being exceeded \cite{TempDVFS}. It can be observed that in some scenarios the operating frequency can oscillate between two frequencies due to DTM and this causes a degradation in power as the chip operates at an unstable frequency \cite{TempDVFS}. To mitigate this, Kim et al. \cite{TempDVFS} proposed a DVFS scheme based on an average frequency operating point so that the frequency is stable. Frequencies are sampled on a periodic basis when they exceed the thermal threshold and an average is formed once enough samples are collected. The samples are stored in a 'frequency window' that gets updated until its full \cite{TempDVFS}. The average of the frequency window is set as the operating point or the 'target frequency' \cite{TempDVFS}. This operating point can be re-sampled for different criteria if, for example, the frequency needs to be lowered or raised. This leads to a reduction in energy and an energy saving of 12.7\% was observed in this scheme \cite{TempDVFS}.

	\begin{figure}[h]
	   \centering
	   \includegraphics[width = 8cm]{DTM}
	   \caption{Temperature aware DVFS scheme (adapted from \cite{TempDVFS}).}
	   \label{Figure:DTM}
	\end{figure}	
	\FloatBarrier


\section{Other techniques}
FPGAs have been used to provide quick, cost effective solutions as they have re-programmable capabilities. Yet this re-configurable overhead is also the reason why they consume more power than ASIC designs as power management is more complex \cite{FPGA}. Tuan et al. \cite{FPGA} have investigated low power FPGA applications for battery powered devices and have used a variety of techniques to reduce power. They designed a low power FPGA called \textit{Pika} \cite{FPGA}. Voltage scaling was used to scale the core operating voltage to drastically reduce energy. A 1V operating voltage was found to give the best reductions without severely affecting performance \cite{FPGA}. It was found that SRAM cells were a major contributor towards leakage current. Subthreshold leakage was reduced by using a higher voltage threshold (Vt) and gate leakage was reduced by using thicker gate oxides \cite{FPGA}. Though this increases cost and area, the overall energy savings outweigh the cons. Finally, power gating was also used to reduce leakage current \cite{FPGA}. Unused blocks were turned off to save power. NMOS transistors were used as power gates as they are faster. Both NMOS and PMOS were not used in conjunction to save area \cite{FPGA}. Power gating in FPGAs is complex due to the amount of logic that can be gated. Therefore establishing what the smallest block that can be power gated is important \cite{FPGA}. In \textit{Pika}, a tile was the smallest unit that was power gated \cite{FPGA}. A tile here is used to define a configurable logic block (CLB) along with its relevant programmable switch matrix that connects it to other CLBs \cite{FPGA}. The SRAM cells in the switch matrix are not power gated to enable state retention when the rest of the core is powered down \cite{FPGA}. Power gating individual tiles helps in implementing a partial standby mode wherein some logic elements can be powered off and the rest can still remain active. This feature is implemented by having a programmable bit per tile \cite{FPGA}. The overall power savings for all these schemes is illustrated in Table \ref{tab:Impact} and it can be seen that a 46\% in active power reduction and 99\% standby power reduction was observed when compared to a normal FPGA with no power management \cite{FPGA}. There was however a trade-off with performance and area to enable these schemes. A 27\% reduction in performance was observed along with a 40\% increase in area. \cite{FPGA}\\

\begin{table}[ht]
\begin{center}

	\begin{tabular}{| c | c | c |}
	\hline
	Technique & Active Power & Standby Power \\ [1ex] \hline 
	Voltage scaling & 35\% & 23\% \\ [1ex] \hline
	Low-leakage SRAM config  & 13\% & 43\% \\ [1ex] \hline
	Power gating & 7\% & N/A \\ [1ex] \hline
	Standby mode & N/A & 51\% \\ [1ex] \hline
	Total power reduction & 46\% & 99\% \\ [1ex] \hline
	\end{tabular}
	\caption{Impact of power reduction techniques (reproduced from \protect\cite{FPGA})}
	\label{tab:Impact}
	
\end{center}	
\end{table}	

Adaptive body biasing is another technique that was found to be beneficial. It is based on the simple idea that forward body biasing (FBB) decreases the threshold voltage and therefore increases performance and power while reverse body biasing (RBB) increases threshold voltage and reduces leakage current \cite{ABB}. This adaptive biasing is only applied to certain areas of the chip to suitably alter performance or power and this can give better power savings. Gammie et al. \cite{ABB} have described a tool, \textit{SmartPriMer}, which inserts power management modules into a piece of RTL code. These modules include power domains, adaptive body biasing and other such techniques to reduce power consumption \cite{ABB}. The tool also generates UPF information for the design that can be used on the later stages of the design flow \cite{ABB}. These techniques were tested on mobile applications and a 37\% reduction in active power was observed \cite{ABB}. Figure \ref{Figure:ABBTech} shows the power reduction achieved when the different techniques are used in a 45nm system on chip (SoC) designed for a mobile phone \cite{ABB}. It can be observed that a mix of Adapative voltage scaling (AVS), RBB and DVFS are used to cut down power when the activity level of a processor is low and least power is consumed when the core is powered down \cite{ABB}.

	\begin{figure}[h]
	   \centering
	   \includegraphics[width = 8cm]{ABBTech}
	   \caption{Power reduction techniques during different processor activities (reproduced from \cite{ABB}).}
	   \label{Figure:ABBTech}
	\end{figure}	
	\FloatBarrier

Finally, a healthy interaction of hardware and software policies is a good way to reduce power \cite{HD/SF}. Most mobile phones have multi core processors so to make optimum use of these resources parallel computing and task scheduling can be used \cite{HD/SF}. Parallel computing involves executing instructions concurrently and an efficient task scheduler can map out a sequence of instructions that can be executed with minimal delay \cite{HD/SF}. The use of heterogeneous cores aids schedulers as cores can be catered to different applications and they make good use of the available resources and help in reducing energy as tasks are executed faster \cite{HD/SF}, \cite{Heterogeneous}, \cite{HeterogenousFuture}. A H-tree clocking implementation helps reducing dynamic power as it reduces wiring capacitance and could be another strategy that can be used \cite{Heterogeneous}.


\section{Conclusion}
The need for low power microcontroller architectures is increasing in the field of wireless sensor networks and mobile applications. Battery life is become a major concern and so different power saving techniques need to be implemented to increase battery life. Various energy efficient techniques were presented in this paper. Asynchronous design highlighted an event based approach for processor design to simplify the architecture and hence reduce power. The memory on any chip is another major contributor towards power consumption and so techniques like adaptive caches, memory compression and memory partitioning were described to reduce power. Subthreshold design was investigated and it was found that for realistic power savings, logic had to be redesigned to cope with low voltages in this region. The use of power domains was another efficient way to reduce power on a chip along with dynamic voltage and frequency scaling (DVFS) although in the latter scheme the on chip temperature had to be considered to make substantial power savings. FPGAs were looked into as an alternative to microcontrollers and it was found that vast power reductions could be made if power management schemes were appropriately added to the FPGA design. Finally, adaptive body biasing and software approaches like parallel computing were proposed as suitable methods to reduce energy consumption in a processor. \\

Many of these techniques can be used together to provide a robust system which consumes less power. There is always a trade-off with performance, cost and area when implementing these techniques but in the long run the energy savings outweigh the cons. Therefore, a more efficient chip can be made which lasts longer and delivers suitable performance.


\appendices

\section*{Acknowledgment}
The author would like to thank Dr. Tom J Kazmierski for his input into this report.


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{IEEEabrv,References}

\end{document}